% Manual compile
% Sweave("systemPipeR.Rnw"); system("pdflatex systemPipeR.tex; bibtex systemPipeR; pdflatex systemPipeR.tex; pdflatex systemPipeR.tex")
% echo 'Sweave("systemPipeR.Rnw")' | R --slave; echo 'Stangle("systemPipeR.Rnw")' | R --slave; pdflatex systemPipeR.tex;  bibtex systemPipeR; pdflatex systemPipeR.tex
% NOTE -- ONLY EDIT THE .Rnw FILE!!!  The .tex file is
% likely to be overwritten.
%
% \VignetteIndexEntry{ChemmineR Tutorial}
% \VignetteDepends{}
% \VignetteKeywords{}
% \VignettePackage{gpls}
\documentclass{article}
<<style, eval=TRUE, echo=FALSE, results=tex>>=
BiocStyle::latex()
@

%\usepackage[authoryear,round]{natbib}
%\bibliographystyle{plainnat}
\def\bibsection{\section{References}}

\usepackage{graphicx}
\usepackage{color}
\usepackage{hyperref}
\usepackage{url}

%\newcommand{\comment}[1]{}
%\newcommand{\Rfunction}[1]{{\texttt{#1}}}
%\newcommand{\Robject}[1]{{\texttt{#1}}}
%\newcommand{\Rpackage}[1]{{\textit{#1}}}
%\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}
%\newcommand{\Rclass}[1]{{\textit{#1}}}
	
% Define header and footer area with fandyhdr package (see: http://www.ctan.org/tex-archive/macros/latex/contrib/fancyhdr/fancyhdr.pdf)
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\rhead{\nouppercase{\leftmark}}
\lhead{\textit{systemPipeR Manual}}
\rfoot{\thepage}

<<echo=FALSE>>=
options(width=95)
unlink("test.db")
@
%\parindent 0in

%\bibliographystyle{plainnat}

\begin{document}
\title{\Rpackage{systemPipeR}: NGS workflow and report generation environment}
\author{Thomas Girke \\
 Email contact: thomas.girke@ucr.edu}
\maketitle

\section{Introduction}

\Rpackage{systemPipeR} provides utilities for building \textit{end-to-end} analysis workflows with automated report generation for next generation sequence (NGS) applications such as RNA-Seq, ChIP-Seq, VAR-Seq and many others. An important feature is support for running command-line software, such as NGS aligners, on both single machines or compute clusters. This includes both interactive job submissions or batch submissions to queuing systems of clusters (tested only with Torque). For instance, \Rpackage{systemPipeR} can be used with most command-line aligners such as \Robject{BWA} \cite{Li2013-oy, Li2009-oc}, \Robject{TopHat 2} \cite{Kim2013-vg} and \Robject{Bowtie 2} \cite{Langmead2012-bs}, as well as the R-based NGS aligner \Rpackage{Rsubread} \cite{Liao2013-bn}. Efficient handling of complex sample sets and experimental designs is facilitated by a well-defined sample annotation infrastructure which improves reproducibility and user-friendliness of many typical analysis workflows in the NGS area. 

\tableofcontents

\section{Getting Started}

\subsection{Installation}
The R software can be downloaded from CRAN (\url{http://cran.at.r-project.org/}) and the \Rpackage{systemPipeR} package from GitHub (\url{https://github.com/tgirke/systemPipeR}). The \Rpackage{systemPipeR} package can be installed from R using the \Rfunction{install.packages} command after downloading and uncompressing the package directory. 
<<eval=FALSE>>=
system("R CMD build systemPipeR") # Builds package
install.packages("systemPipeR.X.X.X.tar.gz", repos=NULL, type="source") # Installs the package
@

\subsection{Loading the Package and Documentation}

<<eval=FALSE, keep.source=TRUE>>=
library("systemPipeR") # Loads the package
library(help="systemPipeR") # Lists all functions and classes 
vignette("systemPipeR") # Opens this PDF manual from R
@

\subsection{Sample FASTQ Files}
The mini sample FASTQ files used by this overview vignette as well as the associated workflow reporting vignettes can be downloaded from \href{http://biocluster.ucr.edu/~tgirke/projects/systemPipeR_test_data.zip}{\textcolor{blue}{here}}. The chosen data set \href{http://www.ncbi.nlm.nih.gov/sra/?term=SRP010938}{\textcolor{blue}{SRP010938}} contains 18 paired-end (PE) read sets from \textit{Arabidposis thaliana} \cite{Howard2013-fq}. To minimize processing time during testing, each FASTQ file has been subsetted to 90,000-100,000 random sampled PE reads that map to the first 100,000 nucleotides of each chromosome of the \textit{A. thalina} genome. The corresponding reference genome sequence (FASTA) and its GFF annotion files (provided in the same download) have been truncated accordingly. This way the entire test sample data set is less than 200MB in storage space. A PE read set has been chosen for this test data set for flexibility, because it can be used for testing both types of analysis routines requiring either SE (single end) reads or PE reads. 

\section{Structure of \Robject{targets} file}
The \Robject{targets} file defines all FASTQ files and sample comparisons of an analysis workflow. The following shows the format of a sample \Robject{targets} file provided by this package. 
<<eval=TRUE, keep.source=TRUE>>=
library(systemPipeR)
targetspath <- paste0(system.file("extdata", package="systemPipeR"), "/targets.txt")
read.delim(targetspath, comment.char = "#")
@

\noindent Structure of \Robject{targets} file for paired end (PE) samples.
<<eval=TRUE, keep.source=TRUE>>=
library(systemPipeR)
targetspath <- paste0(system.file("extdata", package="systemPipeR"), "/targetsPE.txt")
read.delim(targetspath, comment.char = "#")[1:2,1:6]
@

\noindent Comparisons are defined in the header lines of the \Robject{targets} starting with '\texttt{\# <CMP>}'. The 
function \Rfunction{readComp} imports the comparison and stores them in a \Robject{list}.
<<eval=TRUE, keep.source=TRUE>>=
readComp(file=targetspath, format="vector", delim="-")
@

\section{Structure of \Robject{param} file and \Robject{SYSargs} container}
\noindent The \Robject{param} file defines the parameters of the command-line software. The following shows the format of a sample \Robject{param} file provided by this package. 
<<eval=TRUE, keep.source=TRUE>>=
parampath <- paste0(system.file("extdata", package="systemPipeR"), "/tophat.param")
read.delim(parampath, comment.char = "#")
@
\noindent The \Rfunction{systemArgs} function imports the definitions of both the \Robject{param} file and the \Robject{targets} file, and stores all relevant information as \Robject{SYSargs} object.
<<eval=TRUE, keep.source=TRUE>>=   
args <- systemArgs(sysma=parampath, mytargets=targetspath)
args
@
\noindent Several accessor functions are available that are named after the slot names of the \Robject{SYSargs} object class.
<<eval=TRUE, keep.source=TRUE>>=   
names(args)
modules(args)
cores(args)
outpaths(args)[1]
sysargs(args)[1]
@
\noindent The content of the \Robject{param} file can be returned as JSON object as follows (requires \Rpackage{rjson} package).
<<eval=TRUE, keep.source=TRUE>>=   
systemArgs(sysma=parampath, mytargets=targetspath, type="json")
@

\section{Workflow}
\subsection{Define environment settings and samples}
Load package:
<<eval=FALSE, keep.source=TRUE>>=
library(systemPipeR)
@

\noindent Construct \Robject{SYSargs} object from \Robject{param} and \Robject{targets} files.
<<eval=FALSE, keep.source=TRUE>>=
args <- systemArgs(sysma="tophat.param", mytargets="targetsPE.txt")
@

\subsection{FASTQ quality report}
The following \Rfunction{seeFastq} and \Rfunction{seeFastqPlot} functions generate and plot a series of
useful quality statistics for a set of FASTQ files including per cycle quality
box plots, base proportions, base-level quality trends, relative k-mer
diversity, length and occurrence distribution of reads, number of reads above
quality cutoffs and mean quality distribution.  
<<eval=FALSE, keep.source=TRUE>>=
fqlist <- seeFastq(fastq=infile1(args), batchsize=10000, klength=8)
pdf("./results/fastqReport.pdf", height=18, width=4*length(fqlist))
seeFastqPlot(fqlist)
dev.off()
@
\begin{figure}[bthp]
  \centering
   \includegraphics[width=18cm]{fastqReport.pdf}
   \caption{QC report for 18 FASTQ files.}
   \label{fig:fastqreport}
\end{figure}

\subsection{Alignment with Tophat 2}
Build Bowtie 2 index.
<<eval=FALSE, keep.source=TRUE>>=
moduleload(modules(args)) # Skip if module system is not available
system("bowtie2-build ./data/tair10.fasta ./data/tair10.fasta")
@

\noindent Execute \Robject{SYSargs} on a single machine without submitting to a queuing system of a compute cluster.
<<eval=FALSE, keep.source=TRUE>>=
bampaths <- runCommandline(args=args)
@

\noindent Submit to compute nodes.
<<eval=FALSE, keep.source=TRUE>>=0
qsubargs <- getQsubargs(queue="batch", cores=cores(args), memory="mem=10gb", time="walltime=20:00:00")
(joblist <- qsubRun(args=args, qsubargs=qsubargs, Nqsubs=18, package="systemPipeR"))
@

\noindent Alignment Stats
<<eval=FALSE, keep.source=TRUE>>=
read_statsDF <- alignStats(args, fqgz=TRUE) 
write.table(read_statsDF, "results/alignStats.xls", row.names=FALSE, quote=FALSE, sep="\t")
@

\subsection{Create symbolic links for viewing BAM files in IGV}
<<eval=FALSE, keep.source=TRUE>>=
symLink2bam(sysargs=args, htmldir=c("~/.html/", "somedir/"), 
            urlbase="http://myserver.edu/~username/", 
	    urlfile="IGVurl.txt")
@

\subsection{Alignment with Bowtie 2 (here for miRNA profiling experiment)}
Run as single process without submitting to cluster, e.g. via qsub -I.
<<eval=FALSE, keep.source=TRUE>>=
args <- systemArgs(sysma="bowtieSE.param", mytargets="targets.txt")
bampaths <- runCommandline(args=args)
@

\noindent Submit to compute nodes
<<eval=FALSE, keep.source=TRUE>>=
qsubargs <- getQsubargs(queue="batch", cores=cores(args), memory="mem=10gb", time="walltime=20:00:00")
(joblist <- qsubRun(args=args, qsubargs=qsubargs, Nqsubs=18, package="systemPipeR"))
@

\subsection{Read counting for mRNA profiling experiments}
Create txdb (do only once)
<<eval=FALSE, keep.source=TRUE>>=
library(GenomicFeatures)
txdb <- makeTranscriptDbFromGFF(file="data/tair10.gff", format="gff", dataSource="TAIR", species="A. thaliana")
saveDb(txdb, file="./data/tair10.sqlite")
@

\noindent Read counting with summarizeOverlaps in parallel mode with multiple cores
<<eval=FALSE, keep.source=TRUE>>=
library(BiocParallel)
txdb <- loadDb("./data/tair10.sqlite")
eByg <- exonsBy(txdb, by="gene")
bfl <- BamFileList(outpaths(args), yieldSize=50000, index=character())
multicoreParam <- MulticoreParam(workers=4); register(multicoreParam); registered()
counteByg <- bplapply(bfl, function(x) summarizeOverlaps(eByg, x, mode="Union", ignore.strand=TRUE, inter.feature=TRUE, singleEnd=TRUE)) # Note: for strand-specific RNA-Seq set 'ignore.strand=FALSE' and for PE data set 'singleEnd=FALSE'
countDFeByg <- sapply(seq(along=counteByg), function(x) assays(counteByg[[x]])$counts)
rownames(countDFeByg) <- names(rowData(counteByg[[1]])); colnames(countDFeByg) <- names(bfl)
rpkmDFeByg <- apply(countDFeByg, 2, function(x) returnRPKM(counts=x, ranges=eByg))
write.table(countDFeByg, "results/countDFeByg.xls", col.names=NA, quote=FALSE, sep="\t")
write.table(rpkmDFeByg, "results/rpkmDFeByg.xls", col.names=NA, quote=FALSE, sep="\t")
@

\subsection{Read counting for miRNA profiling experiments}
Download miRNA genes from miRBase
<<eval=FALSE, keep.source=TRUE>>=
system("wget ftp://mirbase.org/pub/mirbase/19/genomes/My_species.gff3 -P ./data/")
gff <- import.gff("./data/My_species.gff3", asRangedData=FALSE)
gff <- split(gff, elementMetadata(gff)$ID)
bams <- names(bampaths); names(bams) <- targets$SampleName
bfl <- BamFileList(bams, yieldSize=50000, index=character())
countDFmiR <- summarizeOverlaps(gff, bfl, mode="Union", ignore.strand=FALSE, inter.feature=FALSE) # Note: inter.feature=FALSE important since pre and mature miRNA ranges overlap
rpkmDFmiR <- apply(countDFmiR, 2, function(x) returnRPKM(counts=x, gffsub=gff))
write.table(assays(countDFmiR)$counts, "results/countDFmiR.xls", col.names=NA, quote=FALSE, sep="\t")
write.table(rpkmDFmiR, "results/rpkmDFmiR.xls", col.names=NA, quote=FALSE, sep="\t")
@

\subsection{Correlation analysis of samples}
<<eval=FALSE, keep.source=TRUE>>=
library(ape)
rpkmDFeByg <- read.table("./results/rpkmDFeByg.xls", check.names=FALSE)
rpkmDFeByg <- rpkmDFeByg[rowMeans(rpkmDFeByg) > 50,]
d <- cor(rpkmDFeByg, method="spearman")
hc <- hclust(as.dist(1-d))
plot.phylo(as.phylo(hc), type="p", edge.col="blue", edge.width=2, show.node.label=TRUE, no.margin=TRUE)
@
\begin{figure}[bthp]
  \centering
   \includegraphics[width=6cm]{sample_tree.pdf}
   \caption{Correlation dendrogram of samples.}
   \label{fig:sample_tree}
\end{figure}

\subsection{DEG analysis with \Rpackage{edgeR}} 
<<eval=TRUE, keep.source=TRUE>>=
library(edgeR)
targets <- read.delim(targetspath, comment="#")
cmp <- readComp(file=targetspath, format="matrix", delim="-")
cmp[[1]]
@
Run \Rpackage{edgeR}
<<eval=FALSE, keep.source=TRUE>>=
edgeDF <- run_edgeR(countDF=countDFeByg, targets=targets, cmp=cmp[[1]], independent=FALSE, mdsplot="")
@
Filter and plot DEG results for up and down regulated genes. Because of the toy sample set used in this vignette, the \Rfunarg{FDR} value has been set to a relatively high threshold (here 10\%). More commonly used \Rfunarg{FDR} cutoffs are 1\% or 5\%.
<<eval=FALSE, keep.source=TRUE>>=
DEG_list <- filterDEGs(degDF=edgeDF, filter=c(Fold=2, FDR=10))
@
\begin{figure}[bthp]
  \centering
   \includegraphics[width=10cm]{DEGcounts.pdf}
   \caption{Up and down regulated DEGs.}
   \label{fig:DEGcounts}
\end{figure}
<<eval=FALSE, keep.source=TRUE>>=
names(DEG_list)
DEG_list$Summary
@

\section{Version Information}
<<sessionInfo, results=tex, print=TRUE>>=
toLatex(sessionInfo())
@

\section{Funding}
This software was developed with funding from the National Science Foundation: \href{http://www.nsf.gov/awardsearch/showAward?AWD_ID=1021969}{{\textcolor{blue}{MCB-1021969 }}}.


\bibliography{bibtex}

\end{document}
